{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicholas Whisman: 29 Jan 2021\n",
    "# This Script takes the preprocessor and processor from the 8k Audio project and mashes them into one script\n",
    "#\n",
    "# Ideally, end-game, this script will look over the audio files in the server (be it by file system or database)\n",
    "# analyze them, and train/re-train the model completely over again. \n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------#\n",
    "# Import libraries and dependencies. ML is scary, so there's a lot. Keep it simple.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from librosa import display\n",
    "import librosa\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from numpy import genfromtxt\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 3555/8732 [08:39<12:40,  6.80it/s]/home/daedalus/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
      "  warnings.warn(\n",
      " 95%|█████████▌| 8324/8732 [19:57<00:42,  9.55it/s]/home/daedalus/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
      "  warnings.warn(\n",
      " 95%|█████████▌| 8328/8732 [19:57<00:32, 12.31it/s]/home/daedalus/.local/lib/python3.8/site-packages/librosa/core/spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
      "  warnings.warn(\n",
      "100%|██████████| 8732/8732 [20:52<00:00,  6.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###PRE-PROCESSOR###\n",
    "#-----------------------------------------------------------------#\n",
    "\n",
    "#forming a panda dataframe from the metadata file\n",
    "data=pd.read_csv(\"UrbanSound8K/metadata/UrbanSound8K.csv\")\n",
    "\n",
    "#head of the dataframe\n",
    "data.head()\n",
    "\n",
    "#count of datapoints in each of the folders\n",
    "data[\"fold\"].value_counts()\n",
    "\n",
    "#preprocessing using only mfcc\n",
    "x_train=[]\n",
    "x_test=[]\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "path=\"UrbanSound8K/audio/fold\"\n",
    "for i in tqdm(range(len(data))):\n",
    "    fold_no=str(data.iloc[i][\"fold\"])\n",
    "    file=data.iloc[i][\"slice_file_name\"]\n",
    "    label=data.iloc[i][\"classID\"]\n",
    "    filename=path+fold_no+\"/\"+file\n",
    "    #print(filename)\n",
    "    y,sr=librosa.load(filename)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y, sr, n_mfcc=40).T,axis=0)\n",
    "    #print(mfccs.shape,mfccs.max(),mfccs.min())\n",
    "    if(fold_no!='10'):\n",
    "      x_train.append(mfccs)\n",
    "      y_train.append(label)\n",
    "    else:\n",
    "      x_test.append(mfccs)\n",
    "      y_test.append(label)\n",
    "        \n",
    "len(x_train)+len(x_test)\n",
    "len(data)\n",
    "\n",
    "#converting the lists into numpy arrays\n",
    "x_train=np.array(x_train)\n",
    "x_test=np.array(x_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape\n",
    "\n",
    "#saving the data numpy arrays\n",
    "np.savetxt(\"train_data.csv\", x_train, delimiter=\",\")\n",
    "np.savetxt(\"test_data.csv\",x_test,delimiter=\",\")\n",
    "np.savetxt(\"train_labels.csv\",y_train,delimiter=\",\")\n",
    "np.savetxt(\"test_labels.csv\",y_test,delimiter=\",\")\n",
    "\n",
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "158/158 [==============================] - 3s 14ms/step - loss: 1.9949 - accuracy: 0.2812 - val_loss: 1.3105 - val_accuracy: 0.5759\n",
      "Epoch 2/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 1.1906 - accuracy: 0.5861 - val_loss: 1.2555 - val_accuracy: 0.5783\n",
      "Epoch 3/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.9029 - accuracy: 0.6967 - val_loss: 1.1256 - val_accuracy: 0.6117\n",
      "Epoch 4/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.7259 - accuracy: 0.7538 - val_loss: 1.2591 - val_accuracy: 0.5926\n",
      "Epoch 5/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.6137 - accuracy: 0.7896 - val_loss: 1.3053 - val_accuracy: 0.6153\n",
      "Epoch 6/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.5247 - accuracy: 0.8230 - val_loss: 1.2651 - val_accuracy: 0.5818\n",
      "Epoch 7/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.4266 - accuracy: 0.8554 - val_loss: 1.3071 - val_accuracy: 0.6129\n",
      "Epoch 8/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.3898 - accuracy: 0.8673 - val_loss: 1.3653 - val_accuracy: 0.6177\n",
      "Epoch 9/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.3821 - accuracy: 0.8735 - val_loss: 1.3836 - val_accuracy: 0.6189\n",
      "Epoch 10/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.3570 - accuracy: 0.8782 - val_loss: 1.3827 - val_accuracy: 0.5974\n",
      "Epoch 11/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.3106 - accuracy: 0.8903 - val_loss: 1.5454 - val_accuracy: 0.6093\n",
      "Epoch 12/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.2851 - accuracy: 0.9090 - val_loss: 1.6373 - val_accuracy: 0.5818\n",
      "Epoch 13/30\n",
      "158/158 [==============================] - 2s 13ms/step - loss: 0.2873 - accuracy: 0.9035 - val_loss: 1.5136 - val_accuracy: 0.6165\n",
      "Epoch 14/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.2726 - accuracy: 0.9082 - val_loss: 1.4647 - val_accuracy: 0.6081\n",
      "Epoch 15/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.2421 - accuracy: 0.9154 - val_loss: 1.5887 - val_accuracy: 0.6201\n",
      "Epoch 16/30\n",
      "158/158 [==============================] - 2s 13ms/step - loss: 0.2326 - accuracy: 0.9282 - val_loss: 1.7573 - val_accuracy: 0.5866\n",
      "Epoch 17/30\n",
      "158/158 [==============================] - 2s 13ms/step - loss: 0.2058 - accuracy: 0.9311 - val_loss: 1.6134 - val_accuracy: 0.5842\n",
      "Epoch 18/30\n",
      "158/158 [==============================] - 2s 13ms/step - loss: 0.2020 - accuracy: 0.9294 - val_loss: 1.5653 - val_accuracy: 0.6201\n",
      "Epoch 19/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.2051 - accuracy: 0.9369 - val_loss: 1.8278 - val_accuracy: 0.5651\n",
      "Epoch 20/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.1680 - accuracy: 0.9458 - val_loss: 1.6422 - val_accuracy: 0.6356\n",
      "Epoch 21/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.1714 - accuracy: 0.9418 - val_loss: 1.7912 - val_accuracy: 0.6022\n",
      "Epoch 22/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.1634 - accuracy: 0.9461 - val_loss: 1.7101 - val_accuracy: 0.6165\n",
      "Epoch 23/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.1833 - accuracy: 0.9386 - val_loss: 1.8166 - val_accuracy: 0.5854\n",
      "Epoch 24/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.1697 - accuracy: 0.9454 - val_loss: 1.7240 - val_accuracy: 0.6344\n",
      "Epoch 25/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.1349 - accuracy: 0.9512 - val_loss: 1.8134 - val_accuracy: 0.5890\n",
      "Epoch 26/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.1501 - accuracy: 0.9470 - val_loss: 1.7928 - val_accuracy: 0.6296\n",
      "Epoch 27/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.1837 - accuracy: 0.9391 - val_loss: 1.7957 - val_accuracy: 0.6165\n",
      "Epoch 28/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.1377 - accuracy: 0.9521 - val_loss: 1.9530 - val_accuracy: 0.6141\n",
      "Epoch 29/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.1656 - accuracy: 0.9495 - val_loss: 1.8523 - val_accuracy: 0.6284\n",
      "Epoch 30/30\n",
      "158/158 [==============================] - 2s 12ms/step - loss: 0.1505 - accuracy: 0.9471 - val_loss: 1.9492 - val_accuracy: 0.6320\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.9894\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 1.9492 - accuracy: 0.6320\n",
      "[0.032095491886138916, 0.9893603324890137]\n",
      "[1.949199914932251, 0.6320191025733948]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 40, 1, 64)         1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 20, 1, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 1, 128)        204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               327936    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 671,242\n",
      "Trainable params: 671,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: urbanClassifier/assets\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp25vkrtza/assets\n",
      "float32\n",
      "(1, 40, 1, 1)\n",
      "[[1.4123665e-14 1.2464307e-10 3.1873806e-06 9.9999607e-01 1.2550971e-07\n",
      "  7.4016201e-12 1.4202996e-08 5.6142919e-14 6.4906294e-07 3.5746992e-09]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daedalus/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "### Processing/ Training ###\n",
    "#------------------------------------------------#\n",
    "\n",
    "#extracting data from csv files into numpy arrays\n",
    "x_train = genfromtxt('train_data.csv', delimiter=',')\n",
    "y_train = genfromtxt('train_labels.csv', delimiter=',')\n",
    "x_test = genfromtxt('test_data.csv', delimiter=',')\n",
    "y_test = genfromtxt('test_labels.csv', delimiter=',')\n",
    "\n",
    "#shape\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape\n",
    "\n",
    "#converting to one hot\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "y_train.shape,y_test.shape\n",
    "\n",
    "#reshaping to shape required by CNN\n",
    "x_train=np.reshape(x_train,(x_train.shape[0], 40,1,1))\n",
    "x_test=np.reshape(x_test,(x_test.shape[0], 40,1,1))\n",
    "\n",
    "#shapes\n",
    "x_train.shape,x_test.shape\n",
    "\n",
    "#forming model\n",
    "model=Sequential()\n",
    "\n",
    "#adding layers and forming the model\n",
    "model.add(Conv2D(64,kernel_size=5,strides=1,padding=\"Same\",activation=\"relu\",input_shape=(40,1,1)))\n",
    "model.add(MaxPooling2D(padding=\"same\"))\n",
    "\n",
    "model.add(Conv2D(128,kernel_size=5,strides=1,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(padding=\"same\"))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(10,activation=\"softmax\"))\n",
    "\n",
    "#compiling\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "#training the model\n",
    "model.fit(x_train,y_train,batch_size=50,epochs=30,validation_data=(x_test,y_test))\n",
    "\n",
    "#train and test loss and scores respectively\n",
    "train_loss_score=model.evaluate(x_train,y_train)\n",
    "test_loss_score=model.evaluate(x_test,y_test)\n",
    "print(train_loss_score)\n",
    "print(test_loss_score)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.save('urbanClassifier')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TF Lite model.\n",
    "with tf.io.gfile.GFile('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "x_test[0].shape\n",
    "\n",
    "testData = np.expand_dims(x_test[5],axis=0)\n",
    "prediction = model.predict_classes(testData)\n",
    "prediction\n",
    "y_test[5]\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_details\n",
    "\n",
    "testData = np.expand_dims(x_test[5],axis=0)\n",
    "atData = np.float32(testData)\n",
    "\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], atData)\n",
    "print(input_data.dtype)\n",
    "print(testData.shape)\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
